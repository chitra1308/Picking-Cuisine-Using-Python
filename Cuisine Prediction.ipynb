{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_json('train.json')\n",
    "traindf['ingredients_clean_string'] = [' , '.join(z).strip() for z in traindf['ingredients']]  \n",
    "traindf['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in traindf['ingredients']]       \n",
    "\n",
    "testdf = pd.read_json('test.json') \n",
    "testdf['ingredients_clean_string'] = [' , '.join(z).strip() for z in testdf['ingredients']]\n",
    "testdf['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in testdf['ingredients']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\partheban\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "corpustr = traindf['ingredients_string']\n",
    "vectorizertr = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range = ( 1 , 1 ),analyzer=\"word\", \n",
    "                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)\n",
    "tfidftr=vectorizertr.fit_transform(corpustr).todense()\n",
    "corpusts = testdf['ingredients_string']\n",
    "vectorizerts = TfidfVectorizer(stop_words='english')\n",
    "tfidfts=vectorizertr.transform(corpusts)\n",
    "\n",
    "predictors_tr = tfidftr\n",
    "\n",
    "targets_tr = traindf['cuisine']\n",
    "\n",
    "predictors_ts = tfidfts\n",
    "\n",
    "\n",
    "#classifier = LinearSVC(C=0.80, penalty=\"l2\", dual=False)\n",
    "parameters = {'C':[1, 10]}\n",
    "clf = LinearSVC()\n",
    "#clf = LogisticRegression()\n",
    "\n",
    "classifier = GridSearchCV(clf, parameters)\n",
    "\n",
    "classifier=classifier.fit(predictors_tr,targets_tr)\n",
    "predictions=classifier.predict(predictors_ts)\n",
    "testdf['cuisine'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf[['id' , 'cuisine' ]].to_csv('C:\\\\Users\\\\partheban\\\\submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
